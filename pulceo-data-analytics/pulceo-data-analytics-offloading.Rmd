---
title: "PULCEO Data Analytics  - Task Scheduling/Offloading" 
# author:
#   - name: "Author Name"
#     affiliation: "Your Institution"
#     email: "your.email@example.com"
# date: "`r Sys.Date()`"
# output: rticles::lncs_article
---

```{r, include=FALSE}
# set this option in the first code chunk in the document
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, include = FALSE)
```

```{r warning=FALSE, echo=FALSE}
library(tidyverse)
library(stringi)
library(rjson)
library(kableExtra)
library(gridExtra)
library(ggpubr)
library(data.table)
library(jsonlite)
library(rjson)
library(lubridate) # TODO: *remove*
library(rticles)
library(tinytex)
```

```{r}
# TODO: general package
SavePlot <- function(filename, plot, width = 4, height = 3) {
    ggsave(paste0("plots/", SUBFOLDER, "/", filename), plot + theme(plot.margin = margin(0, 0, 0, 0, "pt")), width = width, height = height, device = cairo_pdf)
}
```


```{r include=TRUE, echo=FALSE}
SUBFOLDER <- "summersoc2025"
```

```{r}
tasks <- read.csv(paste("raw", SUBFOLDER, "TASKS.csv", sep = "/"), skip = 3)

# format
TransformTasks <- function(df) {
    df <- df %>%
        select(
            policy, batchSize, layer, modifiedBy, modifiedById, modifiedOn, newStatus, previousStatus,
            taskSchedulingUUID, taskUUID, timestamp
        ) %>%
        mutate(Run = case_when(
            layer == "cloud-only" ~ "1",
            layer == "edge-only" ~ "2",
            layer == "joint" ~ "3",
            TRUE ~ policy
        ))

    # Transform all columns except 'timestamp' to factors
    df <- df %>%
        mutate(across(-c(timestamp, modifiedOn), as.factor)) %>%
        mutate(
            timestamp = ymd_hms(timestamp, tz = "UTC"),
            modifiedOn = ymd_hms(modifiedOn, tz = "UTC")
        )

    return(df)
}

# Apply the transformation
tasks <- TransformTasks(tasks)
```

```{r}
requests <- read.csv(paste("raw", SUBFOLDER, "REQUESTS.csv", sep = "/"), skip = 3)

# Join tasks with requests
requests_combined <- tasks %>%
    select(taskUUID, batchSize, layer) %>%
    inner_join(requests, by = c("taskUUID" = "destinationHost")) %>%
    select(taskUUID, batchSize, layer, requestType, timestamp, unit, X_value, X_field) %>%
    mutate(Run = case_when(
        layer == "cloud-only" ~ "1",
        layer == "edge-only" ~ "2",
        layer == "joint" ~ "3"
    ))
```

```{r}
CalculateTaskSchedulingMetric <- function(df, start_status, end_status, ...) {
    group_by_vars <- enquos(...)
    df %>%
        filter(newStatus %in% c(start_status, end_status)) %>% # Filter relevant statuses
        group_by(taskUUID, !!!group_by_vars) %>% # Group by taskUUID and additional properties
        arrange(modifiedOn) %>% # Ensure chronological order
        summarize(
            time = as.numeric(
                difftime(
                    modifiedOn[newStatus == end_status][1],
                    modifiedOn[newStatus == start_status][1],
                    units = "secs"
                )
            )
        ) %>%
        ungroup() # Remove grouping
}
```

```{r}
# TODO: use
CreateBoxplot <- function(df, title) {
    ggplot(df, aes(y = time)) +
        geom_boxplot(fill = "skyblue", color = "darkblue") +
        labs(
            title = title,
            y = "Time (s)",
            x = ""
        ) +
        theme_minimal()
}
```

## Scheduling/Offloading Metrics

### Task Waiting Time

```{r include=TRUE, echo=FALSE}
waiting_time_total_df <- CalculateTaskSchedulingMetric(tasks, start_status = "NEW", end_status = "RUNNING", policy, batchSize, layer, Run)

waiting_time_on_psm_df <- CalculateTaskSchedulingMetric(tasks, start_status = "NEW", end_status = "SCHEDULED", policy, batchSize, layer, Run)

waiting_time_on_pna_df <- CalculateTaskSchedulingMetric(tasks, start_status = "OFFLOADED", end_status = "RUNNING", policy, batchSize, layer, Run)
```

### Task Scheduling/Offloading Time

```{r include=TRUE, echo=FALSE}
scheduling_time_df <- CalculateTaskSchedulingMetric(tasks, start_status = "SCHEDULED", end_status = "OFFLOADED", policy, batchSize, layer, Run)
```

### Task Processing Time

```{r include=TRUE, echo=FALSE}
processing_time_df <- CalculateTaskSchedulingMetric(tasks, start_status = "RUNNING", end_status = "COMPLETED", policy, batchSize, layer, Run)
```

### Task Completion Time (Makespan)

```{r include=TRUE, echo=FALSE}
completion_time_df <- CalculateTaskSchedulingMetric(tasks, start_status = "NEW", end_status = "COMPLETED", policy, batchSize, layer, Run)
```

```{r}
# Calculate the overall makespan time
CalculateOverallMakespan <- function(df, ...) {
    group_by_vars <- enquos(...)

    # Ensure the dataframe has valid timestamps
    if (nrow(df) == 0) {
        return(NA) # Handle empty dataframe
    }

    # Remove rows with NA in the time column
    df <- df %>%
        filter(!is.na(time))

    # Check again if the dataframe is empty after filtering
    if (nrow(df) == 0) {
        return(NA) # Handle case where all rows had NA
    }

    # Group by the specified variables (if any) and calculate the overall makespan time
    overall_makespan <- df %>%
        group_by(!!!group_by_vars) %>%
        summarize(
            makespan = as.numeric(difftime(max(time), min(time), units = "secs")),
            .groups = "drop"
        )

    return(overall_makespan)
}

# Apply the function to completion_time_df
overall_makespan <- CalculateOverallMakespan(completion_time_df, batchSize, layer)
```

```{r}
# Create individual boxplots
boxplot_waiting_total <- ggplot(waiting_time_total_df, aes(x = batchSize, y = time, fill = Run)) +
    geom_boxplot(color = "darkblue") +
    labs(title = "Waiting Time (Total)", y = "Time (s)", x = "Batch Size") +
    theme_minimal() +
    ylim(0, max(waiting_time_total_df$time * 1.10, na.rm = TRUE))

boxplot_waiting_psm <- ggplot(waiting_time_on_psm_df, aes(x = batchSize, y = time, fill = Run)) +
    geom_boxplot(color = "darkblue") +
    labs(title = "Waiting Time (PSM)", y = "Time (s)", x = "Batch Size") +
    theme_minimal()

boxplot_waiting_pna <- ggplot(waiting_time_on_pna_df, aes(x = batchSize, y = time, fill = Run)) +
    geom_boxplot(color = "darkblue") +
    labs(title = "Waiting Time (PNA)", y = "Time (s)", x = "Batch Size") +
    theme_minimal() +
    ylim(0, round(max(waiting_time_on_pna_df$time * 1.10, na.rm = TRUE), 2))

boxplot_scheduling <- ggplot(scheduling_time_df, aes(x = batchSize, y = time, fill = Run)) +
    geom_boxplot(color = "darkblue") +
    labs(title = "Offloading Time", y = "Time (s)", x = "Batch Size") +
    theme_minimal() +
    ylim(0, max(scheduling_time_df$time * 1.10, na.rm = TRUE))

boxplot_processing <- ggplot(processing_time_df, aes(x = batchSize, y = time, fill = Run)) +
    geom_boxplot(color = "darkblue") +
    labs(title = "Processing Time", y = "Time (s)", x = "Batch Size") +
    theme_minimal() +
    ylim(0, max(processing_time_df$time * 1.10, na.rm = TRUE))

boxplot_completion <- ggplot(completion_time_df, aes(x = batchSize, y = time, fill = Run)) +
    geom_boxplot(color = "darkblue") +
    labs(title = "Completion Time", y = "Time (s)", x = "Batch Size") +
    theme_minimal() +
    ylim(0, max(completion_time_df$time * 1.10, na.rm = TRUE))

# Arrange all boxplots in a grid
(task_metrics_combined <- ggarrange(
    boxplot_waiting_psm,
    boxplot_waiting_pna,
    boxplot_waiting_total,
    boxplot_scheduling,
    boxplot_processing,
    boxplot_completion,
    nrow = 2,
    ncol = 3,
    common.legend = TRUE,
    legend = "bottom"
))
```

```{r}
SavePlot("task_metrics.pdf", task_metrics_combined, 8, 6)
```

```{r include=TRUE, echo=FALSE}
CalculateWaitingTimeStats <- function(df, start_status, end_status, metric_name) {
    df %>%
        group_by(batchSize) %>%
        summarize(
            start_status = first(start_status),
            end_status = first(end_status),
            sd_time = sd(time, na.rm = TRUE),
            avg_time = mean(time, na.rm = TRUE),
            .groups = "drop"
        ) %>%
        mutate(metric = metric_name)
}

# Create a LaTeX table for task-metrics
CreateLatexTableForTaskMetrics <- function(stats_df) {
    stats_df %>%
        mutate(
            batchSize = as.character(batchSize),
            avg_sd_time = paste0(round(avg_time, 2), "/", round(sd_time, 2))
        ) %>%
        select(metric, start_status, end_status, batchSize, avg_sd_time) %>%
        pivot_wider(
            names_from = batchSize,
            values_from = avg_sd_time,
        ) %>%
        kable(
            format = "latex",
            label = "tab:task-metric-statistics",
            booktabs = TRUE,
            linesep = c("", "", "\\addlinespace", "", ""),
            escape = FALSE,
            caption = "Task metric statistics for different batch sizes",
            col.names = c("Task metric", "$S_{1}$", "$S_{2}$", "200", "400", "600", "800"),
            align = c("l", "l", "l", "c", "c", "c", "c")
        ) %>%
        add_header_above(c(" " = 1, " " = 2, "Batch size ($\\\\mu/\\\\sigma$)" = 4), escape = FALSE) %>%
        kable_styling(latex_options = c("hold_position", "scale_down"))
}

# Generate the LaTeX table
waiting_time_on_psm_stats <- CalculateWaitingTimeStats(waiting_time_on_psm_df, start_status = "NEW", end_status = "SCHEDULED", "Waiting Time (PSM)")
waiting_time_on_pna_stats <- CalculateWaitingTimeStats(waiting_time_on_pna_df, start_status = "OFFLOADED", end_status = "RUNNING", "Waiting Time (PNA)")
waiting_time_total_stats <- CalculateWaitingTimeStats(waiting_time_total_df, start_status = "NEW", end_status = "RUNNING", "Waiting Time (Total)")
scheduling_time_stats <- CalculateWaitingTimeStats(scheduling_time_df, start_status = "SCHEDULED", end_status = "OFFLOADED", "Offloading Time")
processing_time_stats <- CalculateWaitingTimeStats(processing_time_df, start_status = "RUNNING", end_status = "COMPLETED", "Processing Time")
completion_time_stats <- CalculateWaitingTimeStats(completion_time_df, start_status = "NEW", end_status = "COMPLETED", "Completion Time")

# Combine all statistics into a single dataframe
all_task_metrics_stats <- rbind(
    waiting_time_on_psm_stats,
    waiting_time_on_pna_stats,
    waiting_time_total_stats,
    scheduling_time_stats,
    processing_time_stats,
    completion_time_stats
)

# Create latex table
table_task_metrics <- CreateLatexTableForTaskMetrics(all_task_metrics_stats)

# Save latex table
save_kable(table_task_metrics, paste("latex", SUBFOLDER, "task-metric-statistics.tex", sep = "/"))
```

## Performance Metrics

### Average Response Time

```{r}
# Calculate the average response time
CalculateAverageResponseTime <- function(df, ...) {
    group_by_vars <- enquos(...)

    # Ensure the dataframe is not empty and contains valid response times
    if (nrow(df) == 0 || !("X_value" %in% colnames(df))) {
        return(NA) # Handle empty dataframe or missing column
    }

    # Remove rows with NA in the X_value column
    df <- df %>%
        filter(!is.na(X_value))

    # Group by the specified variables (if any) and calculate the average response time
    avg_response_time <- df %>%
        group_by(!!!group_by_vars) %>%
        summarize(avg_response_time = mean(X_value, na.rm = TRUE), .groups = "drop")

    return(avg_response_time)
}

# Apply the function to the REQUESTS dataframe
average_response_time <- CalculateAverageResponseTime(requests_combined, batchSize, layer, Run)
```

```{r}
# Create a boxplot for X_value in requests
average_response_time_boxplot <- ggplot(requests_combined, aes(x = batchSize, y = X_value, fill = Run)) +
    geom_boxplot(color = "darkblue") +
    labs(
        title = "Response Time",
        x = "Batch Size and Layer",
        y = "Response Time (ms)"
    ) +
    theme_minimal() +
    ylim(0, max(requests_combined$X_value * 1.25, na.rm = TRUE)) +


    # Print the boxplot
    print(average_response_time_boxplot)
```

### Throughput (Task requests/s)

```{r}
# Calculate throughput
CalculateThroughput <- function(df, ...) {
    group_by_vars <- enquos(...)

    # Ensure the dataframe has valid timestamps
    if (nrow(df) == 0) {
        return(NA) # Handle empty dataframe
    }

    # Remove rows with NA in the time column
    df <- df %>%
        filter(!is.na(time))

    # Check again if the dataframe is empty after filtering
    if (nrow(df) == 0) {
        return(NA) # Handle case where all rows had NA
    }

    # Group by the specified variables (if any) and calculate throughput
    throughput <- df %>%
        group_by(!!!group_by_vars) %>%
        summarize(
            total_time_span = as.numeric(difftime(max(time), min(time), units = "secs")),
            total_tasks = n(),
            throughput = total_tasks / total_time_span,
            .groups = "drop"
        )

    return(throughput)
}

# Apply the function to completion_time_df
throughput <- CalculateThroughput(completion_time_df, batchSize, Run)

# Print the throughput
print(paste("Throughput (requests per second):", throughput))
```

```{r}
throughput_bar_chart <- ggplot(throughput, aes(x = batchSize, y = throughput, fill = Run)) +
    geom_bar(stat = "identity", position = "dodge", color = "darkblue") +
    geom_errorbar(aes(ymin = throughput - sd(throughput), ymax = throughput + sd(throughput)),
        position = position_dodge(0.9), width = 0.25, color = "black"
    ) +
    labs(
        title = "Throughput",
        x = "Batch Size",
        y = "Throughput (tasks/s)"
    ) +
    theme_minimal() +
    ylim(0, max(throughput$throughput * 1.25, na.rm = TRUE))

# Print the boxplot
print(throughput_bar_chart)
```

### Task Arrival Rate

```{r}
# Calculate task arrival rate
CalculateTaskArrivalRate <- function(df, ...) {
    group_by_vars <- enquos(...)

    # Filter tasks with newStatus = "NEW"
    new_tasks <- df %>%
        filter(newStatus == "NEW")

    # Ensure there are valid timestamps
    if (nrow(new_tasks) == 0) {
        return(0) # Handle case where no new tasks exist
    }

    # Remove rows with NA in the modifiedOn column
    new_tasks <- new_tasks %>%
        filter(!is.na(modifiedOn))

    # Check again if the dataframe is empty after filtering
    if (nrow(new_tasks) == 0) {
        return(0) # Handle case where all rows had NA
    }

    # Group by the specified variables (if any)
    grouped_tasks <- new_tasks %>%
        group_by(!!!group_by_vars)

    # Calculate task arrival rate for each group
    arrival_rate <- grouped_tasks %>%
        summarize(
            total_time_span = as.numeric(difftime(max(modifiedOn), min(modifiedOn), units = "secs")),
            total_new_tasks = n(),
            arrival_rate = total_new_tasks / total_time_span,
            .groups = "drop"
        )

    return(arrival_rate)
}

# Apply the function to the tasks dataframe
arrival_rate <- CalculateTaskArrivalRate(tasks, batchSize, Run)
```

```{r}
# Create a bar chart for task arrival rate
arrival_rate_bar_chart <- ggplot(arrival_rate, aes(x = batchSize, y = arrival_rate, fill = Run)) +
    geom_bar(stat = "identity", position = "dodge", color = "darkblue") +
    geom_errorbar(aes(ymin = arrival_rate - sd(arrival_rate), ymax = arrival_rate + sd(arrival_rate)),
        position = position_dodge(0.9), width = 0.25, color = "black"
    ) +
    labs(
        title = "Task Arrival Rate",
        x = "Batch Size",
        y = "Arrival Rate (tasks/s)"
    ) +
    theme_minimal() +
    ylim(0, max(arrival_rate$arrival_rate * 1.25, na.rm = TRUE))

# Print the bar chart
print(arrival_rate_bar_chart)
```

```{r}
# Arrange all performance-related charts in a grid
(performance_metrics_combined <- ggarrange(
    average_response_time_boxplot,
    arrival_rate_bar_chart,
    throughput_bar_chart,
    nrow = 1,
    ncol = 3,
    common.legend = TRUE,
    legend = "bottom"
))

# Save the combined performance metrics chart
SavePlot("performance_metrics.pdf", performance_metrics_combined, 8, 3)
```